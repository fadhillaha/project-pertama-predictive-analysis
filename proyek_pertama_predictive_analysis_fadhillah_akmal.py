# -*- coding: utf-8 -*-
"""Proyek Pertama_Predictive Analysis_Fadhillah Akmal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-v_W8MZGWZkc6QDUgDS1ep9YbCiV_xC5

# Predictive Analysis : Prediksi Harga Tiket Pesawat

## Persiapan dan *Load Data*
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
dataset = pd.read_csv('/content/drive/MyDrive/Stuff/Dicoding/ML_Terapan/Clean_Dataset.csv', delimiter=",", index_col=0)
dataset

"""Proses *load* dataset pemesanan tiket pesawat yang didapatkan dari https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction.

Dataset yang didapatkan terdapat 300153 sampel data, dengan 11 kolom data yaitu : airline, flight, source_city, departure_time, stops, arrival_time, destination_city, class, duration, days_left, dan price.

## Visualisasi Data dan *Exploratory Data Analysis*
"""

dataset.info()

"""Variabel pada dataset :
- airline : Nama maskapai
- flight : Nomor penerbangan
- source_city : Kota asal penerbangan
- departure_time : Waktu keberangkatan
- stops : Jumlah pemberhentian
- arrival_time : Waktu tiba
- destination_city : Kota tujuan penerbangan
- class : Kelas penerbangan
- duration : Durasi penerbangan
- days_left : Selang waktu antara pembelian tiket dengan waktu penerbangan
- price : harga tiket penerbangan

Dataset ini jenis variabel sebagai berikut :
- 8 kolom berupa objek yaitu : airline, flight, source_city, departure_time, stops, arrival_time, destination_city, dan class
- 1 kolom berupa float64 yaitu duration
- 2 kolom berupa int64 yaitu days_left dan price.
Kolom price merupakan target fitur yang akan diprediksi
"""

dataset.describe()

"""Fungsi describe() memberikan informasi statistik pada masing-masing kolom yang memiliki data numerik, antara lain:

- Count  adalah jumlah sampel pada data.
- Mean adalah nilai rata-rata.
- Std adalah standar deviasi.
- Min yaitu nilai minimum setiap kolom.
- 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
- 75% adalah kuartil ketiga.
- Max adalah nilai maksimum.

### Pembersihan Data

#### Data Duplikat

Tidak ditemukan data duplikat pada dataset
"""

dataset.duplicated().sum()

"""#### *Missing Value*

Tidak ditemukan data yang hilang pada dataset
"""

dataset.isna().sum()

"""#### Data Outlier

Data outlier merupakan sampel data yang nilainya berbeda secara signifikan dibandingkan terhadap nilai-nilai data lainnya. Terdapat beberapa metode untuk menangani outlier, yang dimana pada kasus ini akan digunakan metode IQR (Interquartile Range)

Outlier akan dapat ditunjukan dengan memanfaatkan visualisasi berupa boxplot


"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.boxplot(x=dataset['duration'])

sns.boxplot(x=dataset['days_left'])

Q1 = dataset.quantile(0.25)
Q3 = dataset.quantile(0.75)
IQR=Q3-Q1
dataset=dataset[~((dataset<(Q1-1.5*IQR))|(dataset>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah drop
dataset.shape

"""Setelah visualisasikan menggunakan boxplot, terlihat terdapat beberapa sampel data yang berupa outlier. Setelah menghilangkan data yang memiliki outlier, dataset memiliki 297920 sampel data.

### Analisis Data

Proses analisis data akan dilakukan menggunakan teknik *univariate data analysis* dan teknik *multivariate data analysis*.

#### Univariate Data Analysis

Teknik *univariate data analysis* merupakan analisis data yang berfokus pada satu variabel pada satu waktu. Teknik ini dilakukan untuk mengetahui distribusi dan frekuensi data dari suatu dataset.

Pertama-tama, dipisahkan terlebih dahulu antara fitur berupa kategori dengan numerik.
"""

categorical_features = ['airline', 'flight', 'source_city', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class', 'duration', 'days_left', 'price']
numerical_features = ['duration', 'days_left']

"""a. Fitur Kategori"""

feature = categorical_features[0]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

import matplotlib.pyplot as plt

feature = categorical_features[1]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count_plt = count.head(20)
count_plt.plot(kind='bar', title="20 Nomor Penerbangan Terbanyak" , figsize = (18,8))

feature = categorical_features[2]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

feature = categorical_features[3]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

feature = categorical_features[4]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

feature = categorical_features[5]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

feature = categorical_features[6]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

feature = categorical_features[7]
count = dataset[feature].value_counts()
percent = 100*dataset[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Dari plot grafik jumlah data terhadap kategori, dapat diketahui bahwa :

- Dari 6 kategori airline dapat ditunjukan maskapai paling banyak pada dataset adalah maskapai Vistara dengan 42.6%.

- Terdapat 1561 nomor penerbangan berbeda yang terdata pada dataset. Data menunjukan bahwa penerbangan kode maskapai UK memiliki jumlah penerbangan paling banyak, dengan nomer penerbangan UK-706 memiliki 3116 penerbangan. Dataset ini memiliki jumlah kategori yang sangat banyak dibandingkan kategori lainnya dengan distribusi yang tidak merata. Beberapa kategori hanya memiliki 1 sampel.

- Dari ke enam kota asal penerbangan, mayoritas penerbangan berasal dari kota Delhi dan Mumbai.

- Dari 6 rentang waktu keberangkatan penerbangan, jumlah penerbangan paling banyak terjadi pada waktu pagi hari.

- Dari jumlah pemberhentian, mayoritas penerbangan akan melakukan satu pemberhentian.

- Waktu tiba penerbangan mayoritas pada waktu sore hingga malam.

- Kota tujuan penerbangan mayoritas bertuju ke kota Mumbai dan Delhi.

- Mayoritas sebanyak 68.9 % merupakan tiket yang dipesan merupakan tiket kelas ekonomi

b. Fitur Numerik
"""

dataset.hist(bins=50, figsize=(10,10))
plt.show()

"""Dari histogram fitur numerik dataset terutama pada fitur 'price', dapat diketahui bahwa :  
- Peningkatan harga tiket pesawat berhubungan dengan penurunan jumlah sampel.   
- Sampel data tiket pesawat mayoritas berada pada harga dibawah 15000.
- Distribusi data cenderung miring ke kanan (right-skewed) dengan distribusi yang tidak simetris. Hal ini akan berimplikasi pada model

#### Multivariate Analysis

Teknik *multivariate data analysis* merupakan analisis data yang melibatkan beberapa variabel pada satu waktu. Teknik ini dilakukan untuk mengetahui hubungan dan pola antara satu variabel dengan variabel lainnya.

a. Fitur Kategori
"""

cat_features = dataset.select_dtypes(include='object').columns.to_list()
cat_features.remove('flight')
for col in cat_features:
  sns.catplot(x=col, y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=dataset, palette="Set3")
  plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))

flight_counts = dataset['flight'].value_counts()
df_top_10 = dataset[dataset['flight'].isin(flight_counts.head(10).index)]
avg_prices = df_top_10.groupby('flight')['price'].mean().reset_index()
count_plt = avg_prices.sort_values(by='price', ascending=False).head(10)
sns.catplot(x='flight', y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=count_plt, palette="Set3")
plt.title("Rata-rata 'price' Relatif terhadap - flight (10 Penerbangan Terbanyak)")

"""Hasil pengamatan pada nilai rata-rata 'price' terhadap fitur kategori dapat
diketahui informasi sebagai berikut :
- Dari fitur 'airline', terlihat bahwa maskapai Vistara dan Air India memiliki rata-rata harga tiket yang lebih tinggi dibandingkan dengan maskapai lainnya. Hal ini menandakan kategori ini memiliki pengaruh terhadap harga
- Dari fitur 'source_city', rata-rata harga tiket berada di sekitar harga 20000. Hal ini menandakan kategori ini memiliki pengaruh yang rendah terhadap harga.
- Dari fitur 'departure_time', waktu 'late_night' memiliki rata-rata harga yang lebih rendah dibandingkan waktu lainnya.
- Dari fitur 'stops', terlihat bahwa jumlah pemberhentian memiliki rata-rata nilai yang berbeda satu sama lainnya. 'one' atau satu pemberhentian memiliki rata-rata harga tertinggi.
- Dari fitur 'arrival time', 3 waktu memiliki rata-rata nilai diatas harga 20000 dengan 3 waktu lainnya berada dibawah 20000. 'late_night' menjadi waktu tiba dengan nilai rata-rata terendah.
- Dari fitur 'destination_city', rata-rata harga tiket berada di sekitar rentang 20000. Hal ini menandakan kategori ini memiliki pengaruh yang rendah terhadap harga.
- Dari fitur 'class', terlihat bahwa harga rata-rata dari kelas ekonomi dan bisnis memiliki perbedaan yang sangat berbeda. Hal ini menandakan kategori ini sangat berpengaruh terhadap harga.
- Dari fitur 'flight', karena jumlah kategori yang sangat banyak, maka hanya dapat ditampilkan 10 penerbangan yang terbanyak. Nilai rata-rata 'price' menurun seiring jumlah penerbangan.

Terlihat dari hasil pengamatan bahwa fitur kategori memiliki pengaruh terhadap target label 'price'

b. Fitur Numerik
"""

sns.pairplot(dataset, diag_kind = 'kde')

"""Hasil pengamatan pada nilai 'price' terhadap fitur numerik dapat
diketahui menggunakan fungsi pairplot(). Pada grafik, hubungan antara 'price' dengan fitur numerik lainnya tidak membentuk pola yang jelas, menandakan korelasi yang lemah.

Korelasi dapat dievaluasi menggunakan koefisien korelasi. Nilai koefisien ini adalah dari -1 hingga 1. Nilai koefisien ini digunakan untuk mengetahui hubungan antar dua variabel, dimana nilai -1 atau 1 menandakan korelasi yang kuat, sedangkan nilai 0 menandakan tidak ada nya korelasi sama sekali. Evaluasi koefisien korelasi dapat dilakukan dengan menggunakan corr().
"""

plt.figure(figsize=(10, 8))
correlation_matrix = dataset.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Dari tabel matriks korelasi, dapat terlihat bahwa fitur 'duration' dan 'days_left' memiliki nilai koefisien yang rendah, yaitu 0.22 dan -0.09. Hal ini menunjukan korelasi yang lemah antara dua variabel tersebut terhadap nilai 'price'. Fitur 'days_left' memiliki nilai korelasi yang sangat kecil yang dapat diasumsikan tidak memiliki hubungan terhadap 'price'

Dari fitur kategori, terdapat fitur 'source_city' dan 'destination_city' yang memiliki pengaruh rendah terhadap nilai 'price'. Fitur numerik 'duration' dan 'days_left' memiliki koefisien korelasi yang kecil terhadap nilai 'price'. Walau fitur-fitur ini memiliki korelasi yang lemah, namun fitur ini akan dipertahankan dikarenakan masih memiliki korelasi terhadap nilai 'price'.

Fitur 'airline' memiliki jumlah kategori yang sangat banyak yang tidak efisien untuk diproses model. Maka fitur 'airline' akan di-drop dari dataset.




"""

dataset.drop(['flight'], inplace=True, axis=1)
dataset

"""## *Data Preparation*

Preparasi data merupakan tahapan yang dilakukan untuk mempersiapkan dataset sebelum dimasukan ke proses pemodelan. Tahapan ini melakukan transformasi pada data agar memiliki bentuk yang cocok ketika dimodelkan nanti. Proses preparasi data yang dilakukan pada bagian ini yaitu :
- Encoding fitur kategori
- Pembagian dataset
- Standarisasi

### Encoding

Proses *encoding* adalah proses mengubah data dari satu bentuk menjadi bentuk lainnya. Proses ini dilakukan untuk mengubah data fitur kategori yang masih berbentuk text menjadi data numerik yang dapat diproses pada pelatihan nantinya.

Salah satu metode *encoding* adalah menggunakan metode *label encoding*. Metode ini merubah setiap nilai kategori menjadi nilai numerik yang unik. Contohnya adalah merubah fitur kategori 'departure_time', seperti 'morning' menjadi 1, 'afternoon' menjadi 2, dan seterusnya. Proses ini dilakukan menggunakan LabelEncoder() dari pustaka scikit-learn.
"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

dataset['airline']=le.fit_transform(dataset['airline']);
dataset['source_city']=le.fit_transform(dataset['source_city']);
dataset['destination_city']=le.fit_transform(dataset['destination_city']);
dataset['departure_time']=le.fit_transform(dataset['departure_time']);
dataset['arrival_time']=le.fit_transform(dataset['arrival_time']);
dataset['stops']= dataset["stops"].replace({'zero':0,'one':1,'two_or_more':2}).astype(int);
dataset['class']= dataset["class"].replace({'Economy':0,'Business':1}).astype(int);

dataset.head()

"""### Pembagian Dataset

Pembagian dataset dilakukan untuk membagi dataset menjadi data latih (*training*) dan data uji (*test*). Proses ini dilakukan untuk menyimpan sebagian data untuk menguji model selain dari data yang digunakan ketika pelatihan.

Pada kasus ini, pembagian dataset dilakukan dengan proporsi 90 % data pelatihan dan 10 % data uji.
"""

from sklearn.model_selection import train_test_split
X = dataset.drop(["price"],axis =1)
y = dataset["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Standarisasi

Proses standarisasi merupakan tahapan yang dilakukan untuk menyeragamkan nilai-nilai pada fitur. Beberapa algoritma *machine learning* seperti regresi linear sangat sensitf terhadap perbedaan skala pada dataset. Proses ini juga akan membuat pemodelan algoritma lebih cepat serta meningkatkan kinerja model.

Proses standarisasi yang digunakan adalah StandardScaler. Teknik ini mamastikan dataset dapat seragam dengan mengubah nilai variabel pada dataset agar memiliki rata-rata (mean) senilai nol dan standar deviasi senilai satu. Hal ini dilakukan dengan cara menghitung mean dan standar deviasi dari setiap fitur, kemudian nilai setiap fitur akan dikurangi dengan mean fitur dan dibagi oleh standar deviasi fitur.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler().fit_transform(X_train)
X_train = pd.DataFrame(scaler, columns=X_train.columns)

X_train

X_train.describe().round(4)

"""Dari deskripsi dataset menunjukan bahwa dataset memiliki mean bernilai nol dan standar deviasi seharga satu.

## *Modelling*

Tahapan ini adalah pembuatan model *machine learning*. Untuk memprediksi harga tiket pesawat, model yang digunakan pada proyek ini adalah model regresi. Algoritma yang digunakan adalah sebagai berikut :
- K-Nearest Neighbor (KNN)
- Random Forest
- Adaptive Boosting
- Extreme Gradient Boosting (XGBoost)


Pertama, membuat dataframe yang akan menyimpan data mengenai pelatihan model
"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting', 'XGBoost'])

"""### K-Nearest Neighbor

Algoritma KNN merupakan algoritma sederhana yang memprediksi nilai dengan cara membandingkan data prediksi terhadap data latihnya. Hal ini dilakukan membandingkan jarak satu sampel ke sampel lainnya dengan memilih sejumlah tetangga terdekat.

Pemilihan nilai k untuk model ini adalah sebesar 50
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=50)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""### Random Forest

Algoritma *random forest* adalah algoritma *supervised learning* yang dapat menyelesaikan kasus klasifikasi atau regresi. Model ini dapat memprediksi nilai dengan kumpulan algoritma *decision tree* yang berbentuk esembel.

Parameter yang digunakan adalah :
- n_estimators = 100
- max_depth = 25
- random_state = 123
- n_jobs = -1 (paralel)
"""

from sklearn.ensemble import RandomForestRegressor

RF = RandomForestRegressor(n_estimators=100, max_depth=25, random_state=123, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""### Adaptive Boosting

Algoritma ini merupakan model ensembel menggunakan serangkaian model dengan prediksi yang lemah dan menggabungkan prediksi model-model tersebut menjadi prediksi yang lebih akurat.

"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=123)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""### Extreme Gradient Boosting (XGBoost)

Algoritma XGBoost adalah model ensembel menggunakan metode *gradient boosting* untuk mendapatkan hasil prediksi akhir. Algoritma ini merupakan pendekatan yang cukup populer dalam penyelesaian kasus klasifikasi ataupun regresi.
"""

!pip install xgboost

import xgboost

xgb = xgboost.XGBRegressor()
xgb.fit(X_train,y_train)
models.loc['train_mse', 'XGBoost'] = mean_squared_error(y_pred=xgb.predict(X_train), y_true=y_train)

"""## Evaluasi

Seluruh model yang telah dilatih akan dievaluasi performanya menggunakan beberapa metrik pengukuran. Metrik yang digunakan untuk mengevaluasi model adalah sebagai berikut :
- Mean Squared Error
- $R^2$
- Mean Absolute Percentage Error


Hal pertama yang dilakukan adalah melakukan standarisasi pada data uji dan menghitung metrik evaluasi dari setiap model.
"""

scaler = StandardScaler().fit_transform(X_test)
X_test = pd.DataFrame(scaler, columns=X_test.columns)

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score ,mean_absolute_percentage_error

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
r2 = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
mape = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting, 'XGBoost' : xgb}

for name, model in model_dict.items():
    y_trainpred = model.predict(X_train)
    y_testpred = model.predict(X_test)
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=y_trainpred)/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=y_testpred)/1e3
    r2.loc[name, 'train'] = r2_score(y_true=y_train, y_pred=y_trainpred)
    r2.loc[name, 'test'] =r2_score(y_true=y_test, y_pred=y_testpred)
    mape.loc[name, 'train'] = mean_absolute_percentage_error(y_true=y_train, y_pred=y_trainpred)
    mape.loc[name, 'test'] = mean_absolute_percentage_error(y_true=y_test, y_pred=y_testpred)

"""Hasil perhitungan metrik yang dilakukan kemudian diplot menjadi grafik agar memudahkan pembacaan."""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)
ax.set_title('Perbandingan Model Berdasarkan MSE')

mse

fig, ax = plt.subplots()
r2.sort_values(by='test', ascending=True).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)
ax.set_title('Perbandingan Model Berdasarkan $R^2$')

r2

fig, ax = plt.subplots()
mape.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)
ax.set_title('Perbandingan Model Berdasarkan MAPE')

mape

"""Dari ketiga metrik yang telah dihitung, algoritma *random forest* menunjukan hasil yang lebih baik dibandingkan tiga algoritma lainnya. Untuk memastikan, dapat dibandingkan hasil prediksi keempat model pada salah satu data uji."""

prediksi = X_test.iloc[3:4].copy()
pred_dict = {'y_true':y_test[3:4]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Dari uji coba prediksi ini, dapat disimpulkan bahwa hasil prediksi dari algoritma *random forest* adalah prediksi yang paling mendekati nilai sebenarnya."""